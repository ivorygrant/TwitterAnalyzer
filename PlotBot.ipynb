{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import json\n",
    "import time\n",
    "import tweepy \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timezone\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Twitter API Keys\n",
    "from config import consumer_key, consumer_secret, access_token, access_token_secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to setup TweepyAPI \n",
    "\n",
    "def TweepyAPI():\n",
    "    \n",
    "    # Setup Tweepy API Authentication\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "    api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())\n",
    "    \n",
    "    return api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that pythonize's time\n",
    "\n",
    "def PythonTime(time):\n",
    "    \n",
    "    # converted time of tweet\n",
    "    conv_time_lt = datetime.strptime(time, \"%a %b %d %H:%M:%S %z %Y\")\n",
    "\n",
    "    # current time\n",
    "    current_time = datetime.now(timezone.utc)\n",
    "\n",
    "    # calculate difference between now and tweet\n",
    "    difftime = current_time - conv_time_lt\n",
    "    \n",
    "    return difftime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that checks my home page for which tweets are less than 5 minutes old, and returns those tweets\n",
    "\n",
    "def CheckTweetTimes():\n",
    "\n",
    "    # Setup authentication\n",
    "    api = TweepyAPI()\n",
    "    \n",
    "    # Pull recent tweets from home page\n",
    "    home_tweets = api.home_timeline()\n",
    "    \n",
    "    # tweets to check \n",
    "    check_tweets = []\n",
    "    \n",
    "    # check which tweets are less than 5 minutes\n",
    "    \n",
    "    for each_tweet in home_tweets:\n",
    "        \n",
    "        # find tweet time\n",
    "        last_tweet_time = each_tweet['created_at']\n",
    "        \n",
    "        # call PythonTime function\n",
    "        difftime = PythonTime(last_tweet_time)\n",
    "    \n",
    "        # conditional to check if the time difference is less than 5 minutes:\n",
    "        # if less than 5 minutes, add the tweet to check_tweets, else do nothing\n",
    "        if difftime.seconds < 300:\n",
    "            \n",
    "            check_tweets.append(each_tweet)\n",
    "    \n",
    "    # return check_tweets\n",
    "    return check_tweets\n",
    "\n",
    "# this function should return a list of tweets that are less than 5 minutes from current time, with all information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function that filters the tweets relevant only to our analysis, tweets that begin with following syntax:\n",
    "# \"@haroonahmad06 Analyze: @______\"\n",
    "\n",
    "def FilterTweets(array):\n",
    "    \n",
    "    # tweets to analyze\n",
    "    tweets_to_analyze = []\n",
    "    \n",
    "    # loop through array of tweets\n",
    "    for each in array:\n",
    "        \n",
    "        # if \"@haroonahmad06 Analyze: \" is in the text of the tweet\n",
    "        if \"@haroonahmad06 Analyze: \" in each['text']:\n",
    "            tweets_to_analyze.append(each)\n",
    "            \n",
    "    return tweets_to_analyze\n",
    "    \n",
    "# This function should return a list of tweets to analyze "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to organize tweets; returns a dataframe\n",
    "def OrganizeTweets(user,dates,texts):\n",
    "        \n",
    "        # Push all information into a DataFrame\n",
    "        combined = [[user],dates,texts]\n",
    "        user_df = pd.DataFrame(combined, ['Tweet Author','Tweet Date','Tweet Text']).T\n",
    "        \n",
    "        # Replace NaNs with target_user (needed due to unequal list length b/w tweet dates/texts and author)\n",
    "        user_df = user_df.fillna(value=user)\n",
    "        \n",
    "        return user_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform Vader Analysis\n",
    "def VaderAnalysis(dataframe):\n",
    "    \n",
    "    # Import dependencies\n",
    "    from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "        \n",
    "    # List to store Vader Values\n",
    "    vader_values = []\n",
    "\n",
    "    # Iterate through each row of column \"Tweet Text\"\n",
    "    for each in zip(dataframe['Tweet Text']):\n",
    "\n",
    "        # Run Vader on each text, and store in vader_values\n",
    "        vader_values.append(analyzer.polarity_scores(each[0]))\n",
    "\n",
    "    # convert vader_values into DataFrame\n",
    "    vader_values_df = pd.DataFrame(vader_values)\n",
    "\n",
    "    # combine DataFrames \n",
    "    user_vader_df = dataframe.join(vader_values_df)\n",
    "    \n",
    "    # Save tweet Author to save file name\n",
    "    target_user = user_vader_df['Tweet Author'][0]\n",
    "\n",
    "    # save final dataframe as csv with user identifying file name\n",
    "    user_vader_df.to_csv(\"User Dataframes/%s.csv\" % target_user)\n",
    "\n",
    "    # return DataFrame for Plot function\n",
    "    return user_vader_df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the compound score using a scatter plot, publish PNG\n",
    "# x range will be tweets ago, number of tweets, x range from -1 to -500, range is 'compound'\n",
    "\n",
    "def PlotUserSentiment(dataframe):\n",
    "    \n",
    "    # plot the scatter plot\n",
    "    tweet_author = dataframe['Tweet Author'][0]\n",
    "    current_date = datetime.now()\n",
    "    x = np.arange(-1,-501,-1)\n",
    "    y = dataframe['compound']\n",
    "\n",
    "    f,ax = plt.subplots(figsize=(16,12))\n",
    "    ax.plot(x,y,marker='o')\n",
    "    plt.title('%s Sentiment Analysis on %s' % (tweet_author, current_date),fontsize=20)\n",
    "    plt.xlabel('Tweets Ago',fontsize=16)\n",
    "    plt.ylabel('Tweet Polarity',fontsize=16)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.grid()\n",
    "    leg = ax.legend(fontsize = 'large')\n",
    "    leg.get_texts()[0].set_text('Compound Score')\n",
    "    leg.set_title(\"%s\" % tweet_author, prop = {'size':'x-large'})\n",
    "    plt.savefig('User Graphs/%s.png' % tweet_author)\n",
    "    \n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# publish plot/tweet with user mention\n",
    "\n",
    "def PublishTweet(user_analyzed,requestor):\n",
    "    \n",
    "    # Setup authentication\n",
    "    api = TweepyAPI()\n",
    "    \n",
    "    # Publish to Home Page and mention requestor of Tweet\n",
    "    api.update_with_media(\"User Graphs/%s.png\" % user_analyzed,\n",
    "                      \"Here is your analysis on %s. Thank you %s, please come again!\" % (user_analyzed,requestor))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AnalyzeTweets(array):\n",
    "    \n",
    "    # If array is empty, say \"There are no new tweets to analyze\"\n",
    "    # else Analyze the Tweet\n",
    "    \n",
    "    if not array:\n",
    "        \n",
    "        print(\"There are no new tweets to analyze\")\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # Setup authentication\n",
    "        api = TweepyAPI()\n",
    "\n",
    "        for each_tweet in array:\n",
    "\n",
    "            # Identify requestor of tweet\n",
    "            requestor = each_tweet['user']['screen_name']\n",
    "            requestor = '@%s' % requestor\n",
    "\n",
    "            # Identify the user to perform analysis on (split the text string, get the last word)\n",
    "            split_tweet_text = each_tweet['text'].split()\n",
    "            target_user = split_tweet_text[-1]\n",
    "            \n",
    "            # Check to see how many statuses there are\n",
    "            # If less than 500 tweet message to user\n",
    "            # If not less than 500 run analysis\n",
    "            if api.get_user(target_user)['statuses_count'] < 500:\n",
    "\n",
    "                api.update_status(\"Sorry %s! I require at least 500 tweets to perform my analysis. It appears that %s \\\n",
    "                does not have 500 tweets :(\" % (requestor,target_user))\n",
    "\n",
    "            else:\n",
    "\n",
    "                # Pull 500 Tweets from user by using loop through pages\n",
    "                tweets_text = []\n",
    "                tweets_date = []\n",
    "\n",
    "                for x in range(1, 26):\n",
    "\n",
    "                    target_user_tweets = api.user_timeline(target_user, page=x)\n",
    "\n",
    "                    #Loop through all tweets and save the text and date\n",
    "                    for tweet in target_user_tweets:\n",
    "\n",
    "                        tweets_text.append(tweet['text'])\n",
    "                        tweets_date.append(tweet['created_at'])\n",
    "\n",
    "                # Call OrganizeTweets function to dataframe the results\n",
    "                user_df = OrganizeTweets(target_user,tweets_date,tweets_text)\n",
    "\n",
    "                # Call VaderAnalysis function on dataframe\n",
    "                df_to_plot = VaderAnalysis(user_df)\n",
    "                \n",
    "                # Call PlotUserSentiment function to plot the dataframe\n",
    "                figure = PlotUserSentiment(df_to_plot)\n",
    "                \n",
    "                # Call PublishTweet to send out the tweet w/ analysis\n",
    "                PublishTweet(target_user,requestor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no new tweets to analyze\n",
      "There are no new tweets to analyze\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-90978fb4cc84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# Once checked, wait 5 minutes then check again\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# Add 1 to the counter prior to re-running the loop, Counter used to check how many times ran?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Steps to successfully analyze and plot a tweet:\n",
    "    # Create an infinite loop that runs every five minutes \n",
    "    # Call CheckTweetTimes to pull all tweets from the home page and check their times if posted < 5 min from now\n",
    "    # Call FilterTweets to filter tweet_list for tweets relevant for analysis\n",
    "    # Call AnalyzeTweets on analyze_this to either: analyze and plot tweets, or return an error message if:\n",
    "        # a) there are less than 500 tweets to analyze\n",
    "        # b) there are no items in the array (analyze_this)\n",
    "\n",
    "counter = 0\n",
    "\n",
    "# Infinite loop\n",
    "while(True):\n",
    "\n",
    "    # Call the CheckTweets function and store result\n",
    "    tweet_list = CheckTweetTimes()\n",
    "    \n",
    "    # Call the FilterTweets function and store result\n",
    "    analyze_this = FilterTweets(tweet_list)\n",
    "    \n",
    "    # Call the AnalyzeTweets function to do the analysis\n",
    "    AnalyzeTweets(analyze_this)\n",
    "\n",
    "    # Once checked, wait 5 minutes then check again\n",
    "    time.sleep(300)\n",
    "\n",
    "    # Add 1 to the counter prior to re-running the loop, Counter used to check how many times ran?\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
